[TOC]

### 缓存面试题

#### 项目中缓存是如何使用的？

> **项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？**

##### 1. 项目中缓存是如何使用的？

这个需要结合具体项目的业务分析。

##### 2. 为什么要用缓存？

用缓存，主要有两个用途：**高性能**、**高并发**。

##### 3. 用了缓存之后会有什么不良后果？

常见的缓存问题有以下几个：

* **缓存与数据库双写不一致**。
* **缓存雪崩、缓存穿透、缓存击穿。**
* **缓存并发竞争**。

#### Redis过期策略

Redis 中有个设置时间过期的功能，即可以对存储在 Redis 中的数据设置一个**过期时间**。作为一个缓存数据库，这是非常实用的。如一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。当 set key 的时候，都可以给一个过期时间，通过过期时间可以指定这个 key 可以存活的时间。

如果假设设置了一批 key 只能存活 1 个小时，那么接下来 1 小时后，Redis 是怎么对这批 key 进行删除的？

**定期删除 + 惰性删除。**

- **惰性删除**：定期删除可能会导致很多过期 key 到了时间并没有被删除掉，只有查的时候发现过期了才删除。

- **定时任务删除**：默认是每隔 100ms 就**随机抽取**一些设置了过期时间的 key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？假如 Redis 存了几十万个 key，每隔 100ms 就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载。

但是仅仅通过设置过期时间还是有问题的。如果定期删除漏掉了很多过期 key，然后也没及时去查，也就没走惰性删除。如果大量过期 key 堆积在内存里，导致 Redis 内存快耗尽了。这时候就会启用 **Redis 内存淘汰机制。**

#### 内存淘汰机制

Redis 内存淘汰机制有以下几个：

* noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，一般不用。
* **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key，这个是**最常用**的。
* allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
* volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key，这个一般不太合适。
* volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key。
* volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除。

#### 生产环境中的Redis是怎么部署的？

看看你了解不了解你们公司的 Redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你的 Redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确保可以进行数据恢复？线上 Redis 给几个 G 的内存？设置了哪些参数？压测后你们 Redis 集群承载多少 QPS？

**Redis cluster，10 台机器，5 台机器部署了 Redis 主实例，另外 5 台机器部署了 Redis 的从实例**，每个主实例挂了一个从实例，5 个节点对外提供读写服务，**每个节点的读写高峰 QPS 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。**

机器是什么配置？**32G 内存+ 8 核 CPU + 1T 磁盘**，但是分配给 Redis 进程的是 10G 内存，一般线上生产环境，Redis 的内存尽量**不要超过 10G，超过 10G 可能会有问题**。

5 台机器对外提供读写，一共有 **50G** 内存。

因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。

#### 如何保证缓存与数据库的双写一致性？

只要用**缓存**，就可能会涉及到缓存与数据库双存储双写，只要是双写，就**一定会有数据一致性的问题**，如何解决一致性问题？

最经典的**缓存 + 数据库读写**的模式，就是 **Cache Aside Pattern**。

* **读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应**。
* **更新的时候，先更新数据库，然后再==删除缓存==。**

**为什么是==删除缓存==，而不是更新缓存？**

因为在复杂点的缓存场景中，缓存不仅是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行**运算**，才能计算出缓存的最新值。

举个例子，对于更新缓存的方案，一个缓存涉及的表的字段，在 1 分钟内就修改了 100 次，那么缓存更新 100 次；但是这个缓存在 1 分钟内**只被读取了 1 次**，有大量的冷数据。而如果是删除缓存的话，那么在 1 分钟内，这个缓存不过就**重新计算一次**而已，开销大幅度降低。

**用到缓存才去算缓存**。**删除缓存而不是更新缓存，就是一个 lazy 计算的思想**，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

问题：**先更新数据库，再删除缓存**。如果**删除缓存失败**了，那么会**导致数据库中是新数据，缓存中是旧数据**，数据就出现了**不一致**。

解决思路：**先删除缓存，再更新数据库**。如果**数据库更新失败了，那么数据库中是旧数据**，缓存中是**空的**，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。

问题：数据发生了变更，先删除了缓存，然后要去修改数据库，**此时还没修改**。一个请求过来，去读缓存，发现缓存空了，去查询数据库，**查到了修改前的旧数据**，放到了**缓存**中。随后数据变更的程序完成了数据库的修改。此时数据库和缓存中的数据不一致了。

**为什么上亿流量高并发场景下，缓存会出现这个问题？**

只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说并发量很低的话，特别是读并发很低，日活就 1 W，那么很少的情况下，会出现刚才描述的那种不一致的场景。但如果日活上亿，每秒并发读可能成千上万，每秒只要有数据更新的请求，就**可能会出现上述的数据库 + 缓存不一致的情况**。

**解决方案如下：**

更新数据的时候，根据**数据的唯一标识**，将操作路由之后，发送到一个 JVM 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行 "读取数据+更新缓存" 的操作，根据唯一标识路由之后，也发送到同一个 JVM 内部队列中。

一个队列对应一个工作线程，每个工作线程**串行**拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。

这里有一个**优化点**，一个队列中，其实**多个更新缓存请求串在一起是没意义的**，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。

待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。

如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。

#### LRU实现

以下是基于 **双向链表 + HashMap** 的 LRU 算法实现，对算法的解释如下：

- **访问**某个节点时，将其从原来的位置**删除**，并重新插入到**链表头部**。这样就能保证链表**尾部**存储的就是**最近最久未使用**的节点，当节点数量**大于**缓存最大空间时就**淘汰**链表尾部的节点。
- 为了使**删除**操作时间复杂度为 **O(1)**，就不能采用遍历的方式找到某个节点。**HashMap** 存储着 **Key 到节点**的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从**双向队列**中删除。

采⽤这两种数据结构的组合，get 操作就可以在 **O(1)** 时间复杂度内完成了。由于 put 操作要删除的节点⼀般是尾部节点，所以可以⽤⼀个变量 tail 时刻记录尾部节点的位置，这样 put 操作也可以在 O(1) 时间内完成了。

先来一个结点类。

```java
private static class LRUNode {
    String key;
    Object value;
    LRUNode next;
    LRUNode pre;

    public LRUNode(String key, Object value) {
        this.key = key;
        this.value = value;
    }
}
```

注意：不管是 put 方法还是 get 方法，**都需要将访问的结点重新放到链表头部**，所以会抽出一个公共的方法。

```java
public class LRUCache {

	Map<String, LRUNode> map = new HashMap<>();
	LRUNode head;
	LRUNode tail;
	// 缓存最⼤容量大于1
	int capacity;

	public LRUCache(int capacity) {
		this.capacity = capacity;
	}

	/** 插入元素 */
	public void put(String key, Object value) {
		// 说明缓存中没有任何元素
		if (head == null) {
			head = new LRUNode(key, value);
			tail = head;
			map.put(key, head);
		}
		// 说明缓存中已经存在这个元素了
		LRUNode node = map.get(key);
		if (node != null) {
			// 更新值
			node.value = value;
			// 把这个结点从链表删除并且插⼊到头结点
			removeAndInsert(node);
		} else {
			// 说明当前缓存不存在这个值
			LRUNode newHead = new LRUNode(key, value);
			// 此处溢出则需要删除最近最近未使用的节点
			if (map.size() >= capacity) {
				map.remove(tail.key);
				// 删除尾结点
				tail = tail.pre;
				tail.next = null;
			}
			map.put(key, newHead);
			// 将新的结点插入链表头部
			newHead.next = head;
			head.pre = newHead;
			head = newHead;
		}
	}

	/** 从缓存中取值 */
	public Object get(String key) {
		LRUNode node = map.get(key);
		// 如果有值则需要将这个结点放到链表头部
		if (node != null) {
			// 把这个节点删除并插⼊到头结点
			removeAndInsert(node);
			return node.value;
		}
		return null;
	}

	private void removeAndInsert(LRUNode node) {
		// 特殊情况先判断，例如该节点是头结点或是尾部节点
		if (node == head) {
			return;
		} else if (node == tail) {
			tail = node.pre;
			tail.next = null;
		} else {
			node.pre.next = node.next;
			node.next.pre = node.pre;
		}
		// 插⼊到头结点
		node.next = head;
		node.pre = null;
		head.pre = node;
		head = node;
	}
}
```

**LinkedHashMap** 也可以用来实现**固定大小**的 LRU 缓存，当 LRU 缓存已经满了的时候，它会把最老的键值对移出缓存。LinkedHashMap 提供了一个称为 **removeEldestEntry**() 的方法，该方法会被 put() 和 putAll() 调用来删除最老的键值对。

```java
class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;

    /**
     * 传递进来最多能缓存多少数据
     */
    public LRUCache(int cacheSize) {
        // true表示让linkedHashMap按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

    /**
     * 钩子方法，通过put新增键值对的时候，若该方法返回true
     * 便移除该map中最老的键和值
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据
        return size() > CACHE_SIZE;
    }
}
```





















